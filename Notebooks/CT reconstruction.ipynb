{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4EaNSxaXsyS"
   },
   "source": [
    "\n",
    "## **Introduction**\n",
    "\n",
    "This notebook aims to present a method for reconstructing computed tomography (CT) images. The base model used is the SIREN architecture. Some hyperparameters can be altered to analyze the architecture's performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qal0Ull53TB4"
   },
   "source": [
    "## Required libraries and methods\n",
    "\n",
    "The most part of the libraries/methods here were taken from the original code of SIREN and others were provided by our tutor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DyfjxyMo27M0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
    "import numpy as np\n",
    "import skimage\n",
    "from skimage.transform import radon, iradon\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "from skimage.filters import gaussian\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "def get_mgrid(sidelen, dim=2):\n",
    "    '''Generates a flattened grid of (x,y,...) coordinates in a range of -1 to 1.\n",
    "    sidelen: int\n",
    "    dim: int'''\n",
    "    tensors = tuple(dim * [torch.linspace(-1, 1, steps=sidelen)])\n",
    "    mgrid = torch.stack(torch.meshgrid(*tensors), dim=-1)\n",
    "    mgrid = mgrid.reshape(-1, dim)\n",
    "    return mgrid\n",
    "\n",
    "def plot_images(original, transformed, num_realizations):\n",
    "    '''Produces a plot of 3 images (Original image, Radon transform and Reconstructed image)\n",
    "    original: numpy array, original image\n",
    "    transformed: numpy array, radon transform projection\n",
    "    num_realizations: int, number of realizations for the radon transform'''\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(original, cmap='gray')\n",
    "    plt.title('Shepp-Logan Phantom')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(transformed, cmap='gray', extent=(0, 180, 0, num_realizations), aspect='auto')\n",
    "    plt.title('Radon Transform')\n",
    "    plt.xlabel('Projection Angle (degrees)')\n",
    "    plt.ylabel('Realizations')\n",
    "\n",
    "    reconstructed = iradon(transformed, theta=np.linspace(0., 180., transformed.shape[1]), circle=True)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(reconstructed, cmap='gray')\n",
    "    plt.title('Reconstructed Image')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_images2(im, sinog, mse, psnr, mssim, num_realizations=180):\n",
    "    '''Produces a plot of 5 images (Reconstructed image, Radon transform, mse error graph, psnr error graph, mssim error graph)\n",
    "    im: numpy array, reconstructed image\n",
    "    sinog: radon transform projection\n",
    "    mse: array, mse error vector\n",
    "    psnr: array, psnr error vector\n",
    "    mssim: array, mssim error vector\n",
    "    num_realizations: number of realizations for the radon transform'''\n",
    "\n",
    "    plt.figure(figsize=(16, 4))\n",
    "\n",
    "    plt.subplot(1, 5, 1)\n",
    "    plt.imshow(im, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.title('Reconstructed Image')\n",
    "\n",
    "    plt.subplot(1, 5, 2)\n",
    "    plt.imshow(sinog, cmap='gray', extent=(0, 180, 0, num_realizations), aspect='auto')\n",
    "    plt.title('Radon Transform')\n",
    "    plt.xlabel('Projection Angle (degrees)')\n",
    "    plt.ylabel('Realizations')\n",
    "\n",
    "    plt.subplot(1, 5, 3)\n",
    "    plt.plot(range(1,len(mse)+1), mse)\n",
    "    plt.title('MSE')\n",
    "\n",
    "    plt.subplot(1, 5, 4)\n",
    "    plt.plot(range(1,len(psnr)+1), psnr)\n",
    "    plt.title('PSNR')\n",
    "\n",
    "    plt.subplot(1, 5, 5)\n",
    "    plt.plot(range(1,len(mssim)+1), mssim)\n",
    "    plt.title('MSSIM')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def radon_transform(image, num_angles):\n",
    "    '''Executes the radon transform\n",
    "    image: numpy array\n",
    "    num_angles: int\n",
    "    '''\n",
    "    angles = torch.linspace(0.0, 180.0, steps=num_angles)\n",
    "    radon_images = []\n",
    "    for angle in angles:\n",
    "        rotated_image = TF.rotate(image.unsqueeze(0), angle.item())\n",
    "        projection = torch.sum(rotated_image.squeeze(0), dim=0)\n",
    "        radon_images.append(projection)\n",
    "\n",
    "    return torch.stack(radon_images, dim=0)\n",
    "\n",
    "def get_img_tensor(im, length1):\n",
    "    '''Transforms a numpy array in a tensor\n",
    "    im: numpy array\n",
    "    length1: int, new size for the image\n",
    "    '''\n",
    "    img = Image.fromarray(im)\n",
    "    transform = Compose([\n",
    "        Resize((length1)),\n",
    "        ToTensor(),\n",
    "        Normalize(torch.Tensor([0.5]), torch.Tensor([0.5]))\n",
    "    ])\n",
    "    img = transform(img)\n",
    "    return img\n",
    "\n",
    "def normalize(data):\n",
    "    '''Data normalization\n",
    "    data: numpy array\n",
    "    '''\n",
    "    max = data.max()\n",
    "    min = data.min()\n",
    "    return (data-min)/(max-min)\n",
    "\n",
    "def Gaussian_Noise(sinog_shape, sigma=1):\n",
    "    '''Generates a gaussian noise\n",
    "    sinog_shape: int tuple, desired size\n",
    "    sigma: float, desired std value\n",
    "    '''\n",
    "    noise = np.random.normal(0, sigma, size =sinog_shape)\n",
    "    return noise\n",
    "\n",
    "#Mean Structural Similarity Index Map\n",
    "def mssim(img1, img2, alpha, beta, gamma):\n",
    "    \"\"\"Return the Structural Similarity Map corresponding to input images img1\n",
    "    and img2\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert to float64 to avoid floating point error and negative values in sigma1_sq or sigma2_sq\n",
    "    img1 = img1.astype(np.float64)\n",
    "    img2 = img2.astype(np.float64)\n",
    "\n",
    "    # Data range\n",
    "    L = np.max(img2) - np.min(img2)\n",
    "\n",
    "    # Parameters from Wang et al. 2004\n",
    "    sigma = 1.5\n",
    "    K1 = 0.01\n",
    "    K2 = 0.03\n",
    "    C1 = (K1*L)**2\n",
    "    C2 = (K2*L)**2\n",
    "\n",
    "    # Convolve images (gaussian or uniform filter) to get mean for each patch\n",
    "    filter_args = {'sigma': sigma, 'truncate': 3.5} # 3.5 is the number of sigmas to match Wang et al. to have filter size=11\n",
    "    mu1 = gaussian(img1)\n",
    "    mu2 = gaussian(img2)\n",
    "\n",
    "    # Multiply images\n",
    "    mu1_sq = mu1*mu1\n",
    "    mu2_sq = mu2*mu2\n",
    "    mu1_mu2 = mu1*mu2\n",
    "\n",
    "    # Convolve images (gaussian or uniform filter) to get variance and covariance for each patch. Remove negative values coming from floating point errors\n",
    "\n",
    "    sigma1_sq = gaussian(img1*img1) - mu1_sq\n",
    "    sigma1_sq[sigma1_sq < 0] = 0\n",
    "    sigma2_sq = gaussian(img2*img2) - mu2_sq\n",
    "    sigma2_sq[sigma2_sq < 0] = 0\n",
    "    sigma12 = gaussian(img1*img2) - mu1_mu2\n",
    "\n",
    "    # Compute luminance, contrast and structure for each patch\n",
    "    luminance =((2*mu1_mu2 + C1)/(mu1_sq + mu2_sq + C1))**alpha\n",
    "    contrast=((2*np.sqrt(sigma1_sq*sigma2_sq) + C2)/(sigma1_sq + sigma2_sq + C2))**beta\n",
    "    structure=((2*sigma12 + C2)/(2*np.sqrt(sigma1_sq*sigma2_sq) + C2))**gamma\n",
    "\n",
    "    # Compute MSSIM\n",
    "    MSSIM=np.mean(luminance*contrast*structure)\n",
    "    return MSSIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fu9sm-Bq3acn"
   },
   "source": [
    "## Siren Model\n",
    "\n",
    "Siren model class, copied from the original code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IxnbhQ0K3MKy"
   },
   "outputs": [],
   "source": [
    "class SineLayer(nn.Module):\n",
    "    # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of omega_0.\n",
    "\n",
    "    # If is_first=True, omega_0 is a frequency factor which simply multiplies the activations before the\n",
    "    # nonlinearity. Different signals may require different omega_0 in the first layer - this is a\n",
    "    # hyperparameter.\n",
    "\n",
    "    # If is_first=False, then the weights will be divided by omega_0 so as to keep the magnitude of\n",
    "    # activations constant, but boost gradients to the weight matrix (see supplement Sec. 1.5)\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                 is_first=False, omega_0=30):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.in_features,\n",
    "                                             1 / self.in_features)\n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0,\n",
    "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return torch.sin(self.omega_0 * self.linear(input))\n",
    "\n",
    "    def forward_with_intermediate(self, input):\n",
    "        # For visualization of activation distributions\n",
    "        intermediate = self.omega_0 * self.linear(input)\n",
    "        return torch.sin(intermediate), intermediate\n",
    "\n",
    "\n",
    "class Siren(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False,\n",
    "                 first_omega_0=40, hidden_omega_0=40.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = []\n",
    "        self.net.append(SineLayer(in_features, hidden_features,\n",
    "                                  is_first=True, omega_0=first_omega_0))\n",
    "\n",
    "        for i in range(hidden_layers):\n",
    "            self.net.append(SineLayer(hidden_features, hidden_features,\n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "\n",
    "        if outermost_linear:\n",
    "            final_linear = nn.Linear(hidden_features, out_features)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0,\n",
    "                                              np.sqrt(6 / hidden_features) / hidden_omega_0)\n",
    "\n",
    "            self.net.append(final_linear)\n",
    "        else:\n",
    "            self.net.append(SineLayer(hidden_features, out_features,\n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "\n",
    "        self.net = nn.Sequential(*self.net)\n",
    "\n",
    "    def forward(self, coords):\n",
    "        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n",
    "        output = self.net(coords)\n",
    "        return output, coords\n",
    "\n",
    "    def forward_with_activations(self, coords, retain_grad=False):\n",
    "        '''Returns not only model output, but also intermediate activations.\n",
    "        Only used for visualizing activations later!'''\n",
    "        activations = OrderedDict()\n",
    "\n",
    "        activation_count = 0\n",
    "        x = coords.clone().detach().requires_grad_(True)\n",
    "        activations['input'] = x\n",
    "        for i, layer in enumerate(self.net):\n",
    "            if isinstance(layer, SineLayer):\n",
    "                x, intermed = layer.forward_with_intermediate(x)\n",
    "\n",
    "                if retain_grad:\n",
    "                    x.retain_grad()\n",
    "                    intermed.retain_grad()\n",
    "\n",
    "                activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = intermed\n",
    "                activation_count += 1\n",
    "            else:\n",
    "                x = layer(x)\n",
    "\n",
    "                if retain_grad:\n",
    "                    x.retain_grad()\n",
    "\n",
    "            activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = x\n",
    "            activation_count += 1\n",
    "\n",
    "        return activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JUHkLJEr5x5j"
   },
   "source": [
    "## Data Model\n",
    "\n",
    "Data model class, also copied from the original code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D_92jwJz3lwR"
   },
   "outputs": [],
   "source": [
    "class ImageFitting(Dataset):\n",
    "    def __init__(self, img, length1):\n",
    "        super().__init__()\n",
    "        img = get_img_tensor(img, length1)\n",
    "        self.pixels = img.permute(1, 2, 0).view(-1, 1)\n",
    "        self.coords = get_mgrid(length1, 2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx > 0: raise IndexError\n",
    "\n",
    "        return self.coords, self.pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4h0W4OqQ5_7S"
   },
   "source": [
    "## Initializing model and data\n",
    "\n",
    "Model initialization, similar to the one provided by the authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 847,
     "status": "ok",
     "timestamp": 1711294728442,
     "user": {
      "displayName": "Aureo Henrique e Silva Marques",
      "userId": "11759006475363718695"
     },
     "user_tz": -60
    },
    "id": "zz4zEJzz4dS9",
    "outputId": "8a9db290-5d58-43b4-fc24-b2c9dc87b72c"
   },
   "outputs": [],
   "source": [
    "# Establish seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "img = skimage.data.shepp_logan_phantom()\n",
    "phantom = ImageFitting(img, 400)\n",
    "dataloader = DataLoader(phantom, batch_size=1, pin_memory=True, num_workers=0)\n",
    "\n",
    "# Change hyperparameter if you need\n",
    "img_siren = Siren(in_features=2, out_features=1, hidden_features=256,\n",
    "                  hidden_layers=3, outermost_linear=True, first_omega_0=50, hidden_omega_0=50)\n",
    "img_siren.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dMLi8Ot76T1z"
   },
   "source": [
    "## Running Model\n",
    "\n",
    "Initializing some auxiliar vectors and running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7VHeX2SRGTff"
   },
   "outputs": [],
   "source": [
    "mse_losses = []\n",
    "psnr_losses = []\n",
    "\n",
    "img_mse_losses = []\n",
    "img_psnr_losses = []\n",
    "img_mssim_losses = []\n",
    "\n",
    "save_diffs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1369799,
     "status": "ok",
     "timestamp": 1711015078258,
     "user": {
      "displayName": "Áureo Henrique E Silva Marques",
      "userId": "07726831431471247833"
     },
     "user_tz": -60
    },
    "id": "cNm3g6kN4tz1",
    "outputId": "e7f3d85c-b37d-4a4f-fcd3-7e8eba6e9c18"
   },
   "outputs": [],
   "source": [
    "total_steps = 6001 # Since the whole image is our dataset, this just means N gradient descent steps.\n",
    "steps_til_summary = 200\n",
    "\n",
    "optim = torch.optim.Adam(lr=1e-4, params=img_siren.parameters())\n",
    "#optim = torch.optim.Adagrad(lr=1e-3, params=img_siren.parameters())\n",
    "\n",
    "num_realizations = 40\n",
    "angles = np.linspace(0, 180, num_realizations, endpoint=False)\n",
    "\n",
    "model_input, ground_truth = next(iter(dataloader))\n",
    "sinog_tensor = radon_transform(ground_truth.cpu().view(400,400)*0.5 + 0.5,num_realizations)\n",
    "\n",
    "noise = Gaussian_Noise(sinog_tensor.shape,2)\n",
    "#noise = np.load(\"noise.npy\")\n",
    "sinog_tensor_bruite = sinog_tensor+noise\n",
    "\n",
    "sinog_tensor_bruite = np.clip(sinog_tensor_bruite, sinog_tensor.min(), sinog_tensor.max())\n",
    "\n",
    "s1 = normalize(sinog_tensor_bruite.detach().numpy())\n",
    "\n",
    "model_input, ground_truth = model_input.cuda(), ground_truth.cuda()\n",
    "i1 = ground_truth.cpu().detach().numpy()\n",
    "\n",
    "best_img = []\n",
    "\n",
    "for step in range(total_steps):\n",
    "\n",
    "    model_output, coords = img_siren.forward(model_input)\n",
    "\n",
    "    pred = model_output.clone()\n",
    "\n",
    "    sinog_aux = radon_transform(pred.cpu().view(400,400),num_realizations)\n",
    "\n",
    "    mse_loss = ((sinog_aux - sinog_tensor_bruite)**2).mean()\n",
    "\n",
    "    s2 = normalize(sinog_aux.detach().numpy())\n",
    "\n",
    "    psnr_loss = peak_signal_noise_ratio(s1, s2)\n",
    "\n",
    "    mse_losses.append(mse_loss.item())\n",
    "    psnr_losses.append(psnr_loss)\n",
    "\n",
    "    img_mse_loss = ((pred.cpu().view(400,400).detach().numpy() - img)**2).mean()\n",
    "    img_psnr_loss = peak_signal_noise_ratio(img, pred.cpu().view(400,400).detach().numpy().astype('float64'))\n",
    "    img_mssim_loss=mssim(np.clip(pred.cpu().view(400,400).detach().numpy().astype('float64'),0,1), img, 0.5, 1, 1)\n",
    "\n",
    "    if step == 0:\n",
    "      best_img_psnr = model_output # for saving best img with psnr\n",
    "      best_psnr = img_psnr_loss\n",
    "\n",
    "      best_img_MSSIM = model_output # for saving best img with MSSIM\n",
    "      best_MSSIM = img_mssim_loss\n",
    "    else:\n",
    "      if best_psnr < img_psnr_loss:\n",
    "        best_img_psnr = model_output # for saving best img with psnr\n",
    "        best_psnr = img_psnr_loss\n",
    "\n",
    "      if best_MSSIM < img_mssim_loss:\n",
    "        best_img_MSSIM = model_output # for saving best img with psnr\n",
    "        best_MSSIM = img_mssim_loss\n",
    "\n",
    "    img_mse_losses.append(img_mse_loss.item())\n",
    "    img_psnr_losses.append(img_psnr_loss)\n",
    "    img_mssim_losses.append(img_mssim_loss)\n",
    "\n",
    "\n",
    "\n",
    "    if not step % steps_til_summary:\n",
    "        print(\"Step %d, Total loss %0.6f\" % (step, mse_loss))\n",
    "\n",
    "        plot_images2(pred.cpu().view(400,400).detach().numpy(), sinog_aux.detach().numpy(), img_mse_losses, img_psnr_losses, img_mssim_losses, num_realizations)\n",
    "\n",
    "    if step > 0 and psnr_loss-psnr_losses[-2] < -2:\n",
    "        print(\"Decrease identified in step %d\" % (step))\n",
    "        #save_diffs.append(abs((model_output - past_output).cpu().view(400,400).detach().numpy()))\n",
    "\n",
    "    optim.zero_grad()\n",
    "    mse_loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "print(\"MSE - IMG:\")\n",
    "print(\"Last epoch - %0.5f\" %(img_mse_losses[-1]))\n",
    "print(\"Minimum value - %0.5f\" %(min(img_mse_losses)))\n",
    "print()\n",
    "\n",
    "print(\"PSNR - IMG:\")\n",
    "print(\"Last epoch - %0.5f\" %(img_psnr_losses[-1]))\n",
    "print(\"Maximum value - %0.5f\" %(max(img_psnr_losses)))\n",
    "print()\n",
    "\n",
    "print(\"MSSIM - IMG:\")\n",
    "print(\"Last epoch - %0.5f\" %(img_mssim_losses[-1]))\n",
    "print(\"Maximum value - %0.5f\" %(max(img_mssim_losses)))\n",
    "print()\n",
    "\n",
    "torch.save(img_siren.state_dict(),'siren_model.pth')\n",
    "print(\"Model saved!\")\n",
    "\n",
    "plt.imshow(best_img_psnr.cpu().view(400,400).detach().numpy(), cmap='gray', vmin=0, vmax=1)\n",
    "plt.title('Best Reconstructed Image - PSNR')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(best_img_MSSIM.cpu().view(400,400).detach().numpy(), cmap='gray', vmin=0, vmax=1)\n",
    "plt.title('Best Reconstructed Image - MSSIM')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"When the best PSNR is : \", best_psnr, \"The best MSSIM is : \", img_mssim_losses[img_psnr_losses.index(best_psnr)])\n",
    "\n",
    "print(\"When the best MSSIM is : \", best_MSSIM, \"The best PSNR is : \", img_psnr_losses[img_mssim_losses.index(best_MSSIM)])\n",
    "\n",
    "print(\"Additionally the best mse and psnr from the sinogram respectively\")\n",
    "\n",
    "print(min(img_mse_losses))\n",
    "print(max(img_psnr_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 860
    },
    "executionInfo": {
     "elapsed": 779,
     "status": "ok",
     "timestamp": 1710788622747,
     "user": {
      "displayName": "Mauricio G",
      "userId": "11362846738805154876"
     },
     "user_tz": -60
    },
    "id": "eEIaH490JAM9",
    "outputId": "554cdba7-a177-4d99-ae9b-db2d45b42c7a"
   },
   "outputs": [],
   "source": [
    "plt.plot(psnr_losses)\n",
    "plt.show()\n",
    "plt.plot(mse_losses)\n",
    "#img_mse_losses.append(img_mse_loss.item())\n",
    "#img_psnr_losses.append(img_psnr_loss)\n",
    "#img_mssim_losses.append(img_mssim_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hja3pkaistYs"
   },
   "source": [
    "## Some other tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "executionInfo": {
     "elapsed": 1112,
     "status": "ok",
     "timestamp": 1711296295413,
     "user": {
      "displayName": "Aureo Henrique e Silva Marques",
      "userId": "11759006475363718695"
     },
     "user_tz": -60
    },
    "id": "gogcU7VSH128",
    "outputId": "81ad8b80-2b4a-44b3-fba2-43a2cb01a5eb"
   },
   "outputs": [],
   "source": [
    "from skimage.transform import radon, iradon\n",
    "num_realizations = 40\n",
    "angles = np.linspace(0, 180, num_realizations, endpoint=False)\n",
    "\n",
    "model_input, ground_truth = next(iter(dataloader))\n",
    "radon_transform = radon(img, theta=angles, circle=True)\n",
    "#sinog_tensor = radon_transform(ground_truth.cpu().view(400,400)*0.5 + 0.5,num_realizations)\n",
    "\n",
    "#noise = Gaussian_Noise(sinog_tensor.shape,2)\n",
    "noise = np.load(\"noise.npy\")\n",
    "sinog_tensor_bruite = radon_transform+noise.T\n",
    "sinog_tensor_bruite = np.clip(sinog_tensor_bruite, radon_transform.min(), radon_transform.max())\n",
    "\n",
    "plt.imshow(sinog_tensor_bruite, cmap='gray', extent=(0, 180, 0, num_realizations), aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.title('Radon Transform')\n",
    "plt.xlabel('Projection Angle (degrees)')\n",
    "plt.ylabel('Realizations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "executionInfo": {
     "elapsed": 1383,
     "status": "ok",
     "timestamp": 1711297692408,
     "user": {
      "displayName": "Aureo Henrique e Silva Marques",
      "userId": "11759006475363718695"
     },
     "user_tz": -60
    },
    "id": "DfZYU9gUJadA",
    "outputId": "3471b954-b271-43a0-af37-027110036248"
   },
   "outputs": [],
   "source": [
    "reconstructed = iradon(sinog_tensor_bruite, theta=np.linspace(0., 180., radon_transform.shape[1]), circle=True)\n",
    "plt.imshow(reconstructed, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1711297755430,
     "user": {
      "displayName": "Aureo Henrique e Silva Marques",
      "userId": "11759006475363718695"
     },
     "user_tz": -60
    },
    "id": "Z6qDbaDMSrcS",
    "outputId": "883ff1fa-cc6b-416d-b236-7856c30d6687"
   },
   "outputs": [],
   "source": [
    "peak_signal_noise_ratio(img, reconstructed)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
