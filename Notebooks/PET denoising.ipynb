{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qal0Ull53TB4"
   },
   "source": [
    "## Imports and auxiliar functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DyfjxyMo27M0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
    "import numpy as np\n",
    "import skimage\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "from skimage.transform import radon, iradon\n",
    "from skimage.filters import gaussian\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "def get_mgrid(length1, dim=2):\n",
    "    '''Generates a flattened grid of (x,y,...) coordinates in a range of -1 to 1.\n",
    "    sidelen: int\n",
    "    dim: int'''\n",
    "    tensors = tuple(dim * [torch.linspace(-1, 1, steps=length1)])\n",
    "    mgrid = torch.stack(torch.meshgrid(*tensors), dim=-1)\n",
    "    mgrid = mgrid.reshape(-1, dim)\n",
    "    return mgrid\n",
    "\n",
    "def plot_images(original, transformed, num_realizations):\n",
    "    '''Produces a plot of 3 images (Original image, Radon transform and Reconstructed image)\n",
    "    original: numpy array, original image\n",
    "    transformed: numpy array, radon transform projection\n",
    "    num_realizations: int, number of realizations for the radon transform'''\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(original, cmap='gray')\n",
    "    plt.title('Shepp-Logan Phantom')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(transformed, cmap='gray', extent=(0, 180, 0, num_realizations), aspect='auto')\n",
    "    plt.title('Radon Transform')\n",
    "    plt.xlabel('Projection Angle (degrees)')\n",
    "    plt.ylabel('Realizations')\n",
    "\n",
    "    reconstructed = iradon(transformed, theta=np.linspace(0., 180., transformed.shape[1]), circle=True)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(reconstructed, cmap='gray')\n",
    "    plt.title('Reconstructed Image')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_images2(img, mse, psnr, mssim):\n",
    "  '''Produces a plot of 5 images (Denoised image, mse error graph, psnr error graph, mssim error graph)\n",
    "    im: numpy array, reconstructed image\n",
    "    mse: array, mse error vector\n",
    "    psnr: array, psnr error vector\n",
    "    mssim: array, mssim error vector'''\n",
    "\n",
    "    #diff = np.abs(img - past_img) # dis was to also get the see in which areas the Ã±odel was changing a lot, deviationg when the learning wasnt good\n",
    "\n",
    "    plt.figure(figsize=(14, 4))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.imshow(img, cmap='gray_r')\n",
    "    plt.colorbar()\n",
    "    plt.title('Image')\n",
    "\n",
    "    # plt.subplot(1, 4, 2)\n",
    "    # plt.imshow(diff, cmap='viridis', aspect='auto')\n",
    "    # # Add colorbar for reference\n",
    "    # plt.colorbar()\n",
    "    # plt.title('Diff')\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.plot(range(1,len(mse)+1), mse)\n",
    "    plt.title('MSE')\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.plot(range(1,len(psnr)+1), psnr)\n",
    "    plt.title('PSNR')\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.plot(range(1,len(mssim)+1), mssim)\n",
    "    plt.title('MSSIM')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def radon_transform(image, num_angles): # It isn't really needed here\n",
    "   '''Executes the radon transform\n",
    "    image: numpy array\n",
    "    num_angles: int\n",
    "    '''\n",
    "    angles = torch.linspace(0.0, 180.0, steps=num_angles)\n",
    "    radon_images = []\n",
    "    for angle in angles:\n",
    "        rotated_image = TF.rotate(image.unsqueeze(0), angle.item())\n",
    "        projection = torch.sum(rotated_image.squeeze(0), dim=0)\n",
    "        radon_images.append(projection)\n",
    "\n",
    "    return torch.stack(radon_images, dim=0)\n",
    "\n",
    "def get_img_tensor(im, length1):\n",
    "  '''Transforms a numpy array in a tensor\n",
    "    im: numpy array\n",
    "    length1: int, new size for the image\n",
    "    '''\n",
    "    img = Image.fromarray(im)\n",
    "    transform = Compose([\n",
    "        Resize((length1)),\n",
    "        ToTensor(),\n",
    "        #Normalize(torch.Tensor([0.5]), torch.Tensor([0.5]))\n",
    "    ])\n",
    "    img = transform(img)\n",
    "    return img\n",
    "\n",
    "def Gaussian_Noise(img_shape, sigma=1):\n",
    "  '''Generates a gaussian noise\n",
    "    sinog_shape: int tuple, desired size\n",
    "    sigma: float, desired std value\n",
    "    '''\n",
    "    np.random.seed(0)\n",
    "    noise = np.random.normal(0, sigma, size =img_shape)\n",
    "    return noise\n",
    "\n",
    "def normalize(data):\n",
    "   '''Data normalization\n",
    "    data: numpy array\n",
    "    '''\n",
    "    max = data.max()\n",
    "    min = data.min()\n",
    "    return (data-min)/(max-min)\n",
    "\n",
    "#Mean Structural Similarity Index Map\n",
    "def mssim(img1, img2, alpha, beta, gamma):\n",
    "    \"\"\"Return the Structural Similarity Map corresponding to input images img1\n",
    "    and img2\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert to float64 to avoid floating point error and negative values in sigma1_sq or sigma2_sq\n",
    "    img1 = img1.astype(np.float64)\n",
    "    img2 = img2.astype(np.float64)\n",
    "\n",
    "    # Data range\n",
    "    L = np.max(img2) - np.min(img2)\n",
    "\n",
    "    # Parameters from Wang et al. 2004\n",
    "    sigma = 1.5\n",
    "    K1 = 0.01\n",
    "    K2 = 0.03\n",
    "    C1 = (K1*L)**2\n",
    "    C2 = (K2*L)**2\n",
    "\n",
    "    # Convolve images (gaussian or uniform filter) to get mean for each patch\n",
    "    filter_args = {'sigma': sigma, 'truncate': 3.5} # 3.5 is the number of sigmas to match Wang et al. to have filter size=11\n",
    "    mu1 = gaussian(img1)\n",
    "    mu2 = gaussian(img2)\n",
    "\n",
    "    # Multiply images\n",
    "    mu1_sq = mu1*mu1\n",
    "    mu2_sq = mu2*mu2\n",
    "    mu1_mu2 = mu1*mu2\n",
    "\n",
    "    # Convolve images (gaussian or uniform filter) to get variance and covariance for each patch. Remove negative values coming from floating point errors\n",
    "\n",
    "    sigma1_sq = gaussian(img1*img1) - mu1_sq\n",
    "    sigma1_sq[sigma1_sq < 0] = 0\n",
    "    sigma2_sq = gaussian(img2*img2) - mu2_sq\n",
    "    sigma2_sq[sigma2_sq < 0] = 0\n",
    "    sigma12 = gaussian(img1*img2) - mu1_mu2\n",
    "\n",
    "    # Compute luminance, contrast and structure for each patch\n",
    "    luminance =((2*mu1_mu2 + C1)/(mu1_sq + mu2_sq + C1))**alpha\n",
    "    contrast=((2*np.sqrt(sigma1_sq*sigma2_sq) + C2)/(sigma1_sq + sigma2_sq + C2))**beta\n",
    "    structure=((2*sigma12 + C2)/(2*np.sqrt(sigma1_sq*sigma2_sq) + C2))**gamma\n",
    "\n",
    "    # Compute MSSIM\n",
    "    MSSIM=np.mean(luminance*contrast*structure)\n",
    "    return MSSIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fu9sm-Bq3acn"
   },
   "source": [
    "## Siren Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IxnbhQ0K3MKy"
   },
   "outputs": [],
   "source": [
    "class SineLayer(nn.Module):\n",
    "    # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of omega_0.\n",
    "\n",
    "    # If is_first=True, omega_0 is a frequency factor which simply multiplies the activations before the\n",
    "    # nonlinearity. Different signals may require different omega_0 in the first layer - this is a\n",
    "    # hyperparameter.\n",
    "\n",
    "    # If is_first=False, then the weights will be divided by omega_0 so as to keep the magnitude of\n",
    "    # activations constant, but boost gradients to the weight matrix (see supplement Sec. 1.5)\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                 is_first=False, omega_0=30):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.in_features,\n",
    "                                             1 / self.in_features)\n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0,\n",
    "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return torch.sin(self.omega_0 * self.linear(input))\n",
    "\n",
    "    def forward_with_intermediate(self, input):\n",
    "        # For visualization of activation distributions\n",
    "        intermediate = self.omega_0 * self.linear(input)\n",
    "        return torch.sin(intermediate), intermediate\n",
    "\n",
    "\n",
    "class Siren(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False,\n",
    "                 first_omega_0=30, hidden_omega_0=30.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = []\n",
    "        self.net.append(SineLayer(in_features, hidden_features,\n",
    "                                  is_first=True, omega_0=first_omega_0))\n",
    "\n",
    "        for i in range(hidden_layers):\n",
    "            self.net.append(SineLayer(hidden_features, hidden_features,\n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "\n",
    "        if outermost_linear:\n",
    "            final_linear = nn.Linear(hidden_features, out_features)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0,\n",
    "                                              np.sqrt(6 / hidden_features) / hidden_omega_0)\n",
    "\n",
    "            self.net.append(final_linear)\n",
    "        else:\n",
    "            self.net.append(SineLayer(hidden_features, out_features,\n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "\n",
    "        self.net = nn.Sequential(*self.net)\n",
    "\n",
    "    def forward(self, coords):\n",
    "        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n",
    "        output = self.net(coords)\n",
    "        return output, coords\n",
    "\n",
    "    def forward_with_activations(self, coords, retain_grad=False):\n",
    "        '''Returns not only model output, but also intermediate activations.\n",
    "        Only used for visualizing activations later!'''\n",
    "        activations = OrderedDict()\n",
    "\n",
    "        activation_count = 0\n",
    "        x = coords.clone().detach().requires_grad_(True)\n",
    "        activations['input'] = x\n",
    "        for i, layer in enumerate(self.net):\n",
    "            if isinstance(layer, SineLayer):\n",
    "                x, intermed = layer.forward_with_intermediate(x)\n",
    "\n",
    "                if retain_grad:\n",
    "                    x.retain_grad()\n",
    "                    intermed.retain_grad()\n",
    "\n",
    "                activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = intermed\n",
    "                activation_count += 1\n",
    "            else:\n",
    "                x = layer(x)\n",
    "\n",
    "                if retain_grad:\n",
    "                    x.retain_grad()\n",
    "\n",
    "            activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = x\n",
    "            activation_count += 1\n",
    "\n",
    "        return activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JUHkLJEr5x5j"
   },
   "source": [
    "## Data Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D_92jwJz3lwR"
   },
   "outputs": [],
   "source": [
    "class ImageFitting(Dataset):\n",
    "    def __init__(self, img, length1):\n",
    "        super().__init__()\n",
    "        img = get_img_tensor(img, length1)\n",
    "        self.pixels = img.permute(1, 2, 0).view(-1, 1)\n",
    "        self.coords = get_mgrid(length1, 2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx > 0: raise IndexError\n",
    "\n",
    "        return self.coords, self.pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4h0W4OqQ5_7S"
   },
   "source": [
    "## Initializing model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "executionInfo": {
     "elapsed": 1141,
     "status": "ok",
     "timestamp": 1711216855367,
     "user": {
      "displayName": "Aureo Henrique e Silva Marques",
      "userId": "11759006475363718695"
     },
     "user_tz": -60
    },
    "id": "8dMdeaOs15eZ",
    "outputId": "03507e5d-ea70-4721-8d3b-c0c03a4d3b51"
   },
   "outputs": [],
   "source": [
    "fo = open(\"/content/out_beta00102522_it30.img\", \"rb\")\n",
    "img = np.fromfile(fo, dtype=np.float32).reshape((400,400))\n",
    "img_norm = normalize(img)\n",
    "plt.imshow(img_norm, cmap=\"gray_r\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "executionInfo": {
     "elapsed": 468,
     "status": "ok",
     "timestamp": 1711194736143,
     "user": {
      "displayName": "Aureo Henrique e Silva Marques",
      "userId": "11759006475363718695"
     },
     "user_tz": -60
    },
    "id": "Llo3BsHK6XzB",
    "outputId": "130cea55-ecd5-4316-859a-3cbc1f482f03"
   },
   "outputs": [],
   "source": [
    "fo = open(\"/content/gt_tep.img\", \"rb\")\n",
    "img_gt = np.fromfile(fo, dtype=np.float32).reshape((400,400))\n",
    "img_gt_norm = normalize(img_gt)\n",
    "# noise = Gaussian_Noise(img.shape, 10).astype(\"float32\")\n",
    "# img_bruite = np.clip(img + noise, img.min(), img.max())\n",
    "# img_bruite = normalize(img_bruite)\n",
    "plt.imshow(img_gt, cmap=\"gray_r\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 441,
     "status": "ok",
     "timestamp": 1711194740291,
     "user": {
      "displayName": "Aureo Henrique e Silva Marques",
      "userId": "11759006475363718695"
     },
     "user_tz": -60
    },
    "id": "QvpTsTjx8PcF",
    "outputId": "06a3c1f9-8993-40d7-de1e-a1c64d61a9aa"
   },
   "outputs": [],
   "source": [
    "peak_signal_noise_ratio(normalize(img),img_gt_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 444,
     "status": "ok",
     "timestamp": 1711201767646,
     "user": {
      "displayName": "Aureo Henrique e Silva Marques",
      "userId": "11759006475363718695"
     },
     "user_tz": -60
    },
    "id": "zz4zEJzz4dS9",
    "outputId": "2921d063-a358-4026-f327-c766fe4eba8d"
   },
   "outputs": [],
   "source": [
    "# Establish seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "#img = skimage.data.shepp_logan_phantom()\n",
    "\n",
    "phantom = ImageFitting(img_norm, 400)\n",
    "dataloader = DataLoader(phantom, batch_size=1, pin_memory=True, num_workers=0)\n",
    "\n",
    "img_siren = Siren(in_features=2, out_features=1, hidden_features=256,\n",
    "                  hidden_layers=3, outermost_linear=True, first_omega_0=50, hidden_omega_0=50)\n",
    "img_siren.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dMLi8Ot76T1z"
   },
   "source": [
    "## Running Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "15EFAy83F8AUuYP-Hic02i_nZ7Soxy4e_"
    },
    "executionInfo": {
     "elapsed": 348549,
     "status": "ok",
     "timestamp": 1711202119037,
     "user": {
      "displayName": "Aureo Henrique e Silva Marques",
      "userId": "11759006475363718695"
     },
     "user_tz": -60
    },
    "id": "cNm3g6kN4tz1",
    "outputId": "c0d9d653-af6d-41e0-986b-7ec6c98b7efe"
   },
   "outputs": [],
   "source": [
    "total_steps = 3001 # Since the whole image is our dataset, this just means 500 gradient descent steps.\n",
    "steps_til_summary = 50\n",
    "\n",
    "optim = torch.optim.Adam(lr=1e-4, params=img_siren.parameters())\n",
    "#optim = torch.optim.Adagrad(lr=1e-3, params=img_siren.parameters())\n",
    "\n",
    "model_input, ground_truth = next(iter(dataloader))\n",
    "model_input, ground_truth = model_input.cuda(), ground_truth.cuda()\n",
    "\n",
    "mse_losses = []\n",
    "psnr_losses = []\n",
    "img_mse_losses = []\n",
    "img_psnr_losses = []\n",
    "img_mssim_losses = []\n",
    "\n",
    "for step in range(total_steps):\n",
    "\n",
    "    if step >0 :\n",
    "      past_output = model_output\n",
    "\n",
    "    model_output, coords = img_siren.forward(model_input)\n",
    "\n",
    "\n",
    "    mse_loss = ((model_output - ground_truth)**2).mean()\n",
    "    psnr_loss = peak_signal_noise_ratio(ground_truth.cpu().detach().numpy(), model_output.cpu().detach().numpy())\n",
    "\n",
    "    mse_losses.append(mse_loss.item())\n",
    "    psnr_losses.append(psnr_loss)\n",
    "\n",
    "    img_mse_loss = ((model_output.cpu().view(400,400).detach().numpy() - img_gt_norm)**2).mean()\n",
    "    img_psnr_loss = peak_signal_noise_ratio(img_gt_norm, normalize(model_output.cpu().view(400,400).detach().numpy().astype('float32')))\n",
    "    img_mssim_loss=mssim(normalize(model_output.cpu().view(400,400).detach().numpy().astype('float32')), img_gt_norm, 0.5, 1, 1)\n",
    "\n",
    "    if step == 0:\n",
    "      best_img_psnr = model_output # for saving best img with psnr\n",
    "      best_psnr = img_psnr_loss\n",
    "\n",
    "      best_img_MSSIM = model_output # for saving best img with MSSIM\n",
    "      best_MSSIM = img_mssim_loss\n",
    "    else:\n",
    "      if best_psnr < img_psnr_loss:\n",
    "        best_img_psnr = model_output # for saving best img with psnr\n",
    "        best_psnr = img_psnr_loss\n",
    "\n",
    "      if best_MSSIM < img_mssim_loss:\n",
    "        best_img_MSSIM = model_output # for saving best img with psnr\n",
    "        best_MSSIM = img_mssim_loss\n",
    "\n",
    "    img_mse_losses.append(img_mse_loss.item())\n",
    "    img_psnr_losses.append(img_psnr_loss)\n",
    "    img_mssim_losses.append(img_mssim_loss)\n",
    "\n",
    "    if step > 0 and not step % steps_til_summary:\n",
    "        print(\"Step %d, Total loss %0.6f\" % (step, mse_loss))\n",
    "\n",
    "        plot_images2(model_output.cpu().view(400,400).detach().numpy(), img_mse_losses, img_psnr_losses, img_mssim_losses)\n",
    "\n",
    "    optim.zero_grad()\n",
    "    mse_loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "print(\"MSE:\")\n",
    "print(\"Last epoch - %0.5f\" %(img_mse_losses[-1]))\n",
    "print(\"Minimum value - %0.5f\" %(min(img_mse_losses)))\n",
    "print()\n",
    "\n",
    "print(\"PSNR:\")\n",
    "print(\"Last epoch - %0.5f\" %(img_psnr_losses[-1]))\n",
    "print(\"Maximum value - %0.5f\" %(max(img_psnr_losses)))\n",
    "print()\n",
    "\n",
    "print(\"MSSIM - IMG:\")\n",
    "print(\"Last epoch - %0.5f\" %(img_mssim_losses[-1]))\n",
    "print(\"Maximum value - %0.5f\" %(max(img_mssim_losses)))\n",
    "print()\n",
    "\n",
    "plt.imshow(best_img_psnr.cpu().view(400,400).detach().numpy(), cmap='gray_r', vmin=0, vmax=1)\n",
    "plt.title('Best Reconstructed Image - PSNR')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(best_img_MSSIM.cpu().view(400,400).detach().numpy(), cmap='gray_r', vmin=0, vmax=1)\n",
    "plt.title('Best Reconstructed Image - MSSIM')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"When the best PSNR is : \", best_psnr, \"The best MSSIM is : \", img_mssim_losses[img_psnr_losses.index(best_psnr)])\n",
    "\n",
    "print(\"When the best MSSIM is : \", best_MSSIM, \"The best PSNR is : \", img_psnr_losses[img_mssim_losses.index(best_MSSIM)])\n",
    "\n",
    "print(\"Additionally the best mse and psnr from the sinogram respectively\")\n",
    "\n",
    "print(min(img_mse_losses))\n",
    "print(max(img_psnr_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 118258,
     "status": "ok",
     "timestamp": 1711195276530,
     "user": {
      "displayName": "Aureo Henrique e Silva Marques",
      "userId": "11759006475363718695"
     },
     "user_tz": -60
    },
    "id": "pzGXg4ekLbWr",
    "outputId": "42107639-c5c2-4a20-ec72-f11862c3dc6d"
   },
   "outputs": [],
   "source": [
    "for step in range(1000):\n",
    "\n",
    "    if step >0 :\n",
    "      past_output = model_output\n",
    "\n",
    "    model_output, coords = img_siren.forward(model_input)\n",
    "\n",
    "\n",
    "    mse_loss = ((model_output - ground_truth)**2).mean()\n",
    "    psnr_loss = peak_signal_noise_ratio(ground_truth.cpu().detach().numpy(), model_output.cpu().detach().numpy())\n",
    "\n",
    "    mse_losses.append(mse_loss.item())\n",
    "    psnr_losses.append(psnr_loss)\n",
    "\n",
    "    img_mse_loss = ((model_output.cpu().view(400,400).detach().numpy() - img_gt_norm)**2).mean()\n",
    "    img_psnr_loss = peak_signal_noise_ratio(img_gt_norm, normalize(model_output.cpu().view(400,400).detach().numpy().astype('float32')))\n",
    "    img_mssim_loss=mssim(normalize(model_output.cpu().view(400,400).detach().numpy().astype('float32')), img_gt_norm, 0.5, 1, 1)\n",
    "\n",
    "    if step == 0:\n",
    "      best_img_psnr = model_output # for saving best img with psnr\n",
    "      best_psnr = img_psnr_loss\n",
    "\n",
    "      best_img_MSSIM = model_output # for saving best img with MSSIM\n",
    "      best_MSSIM = img_mssim_loss\n",
    "    else:\n",
    "      if best_psnr < img_psnr_loss:\n",
    "        best_img_psnr = model_output # for saving best img with psnr\n",
    "        best_psnr = img_psnr_loss\n",
    "\n",
    "      if best_MSSIM < img_mssim_loss:\n",
    "        best_img_MSSIM = model_output # for saving best img with psnr\n",
    "        best_MSSIM = img_mssim_loss\n",
    "\n",
    "    img_mse_losses.append(img_mse_loss.item())\n",
    "    img_psnr_losses.append(img_psnr_loss)\n",
    "    img_mssim_losses.append(img_mssim_loss)\n",
    "\n",
    "    if step > 0 and not step % steps_til_summary:\n",
    "        print(\"Step %d, Total loss %0.6f\" % (step, mse_loss))\n",
    "\n",
    "        plot_images2(model_output.cpu().view(400,400).detach().numpy(), img_mse_losses, img_psnr_losses, img_mssim_losses)\n",
    "\n",
    "    optim.zero_grad()\n",
    "    mse_loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "print(\"MSE:\")\n",
    "print(\"Last epoch - %0.5f\" %(img_mse_losses[-1]))\n",
    "print(\"Minimum value - %0.5f\" %(min(img_mse_losses)))\n",
    "print()\n",
    "\n",
    "print(\"PSNR:\")\n",
    "print(\"Last epoch - %0.5f\" %(img_psnr_losses[-1]))\n",
    "print(\"Maximum value - %0.5f\" %(max(img_psnr_losses)))\n",
    "print()\n",
    "\n",
    "print(\"MSSIM - IMG:\")\n",
    "print(\"Last epoch - %0.5f\" %(img_mssim_losses[-1]))\n",
    "print(\"Maximum value - %0.5f\" %(max(img_mssim_losses)))\n",
    "print()\n",
    "\n",
    "plt.imshow(best_img_psnr.cpu().view(400,400).detach().numpy(), cmap='gray_r', vmin=0, vmax=1)\n",
    "plt.title('Best Reconstructed Image - PSNR')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(best_img_MSSIM.cpu().view(400,400).detach().numpy(), cmap='gray_r', vmin=0, vmax=1)\n",
    "plt.title('Best Reconstructed Image - MSSIM')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"When the best PSNR is : \", best_psnr, \"The best MSSIM is : \", img_mssim_losses[img_psnr_losses.index(best_psnr)])\n",
    "\n",
    "print(\"When the best MSSIM is : \", best_MSSIM, \"The best PSNR is : \", img_psnr_losses[img_mssim_losses.index(best_MSSIM)])\n",
    "\n",
    "print(\"Additionally the best mse and psnr from the sinogram respectively\")\n",
    "\n",
    "print(min(img_mse_losses))\n",
    "print(max(img_psnr_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1705156329634,
     "user": {
      "displayName": "Mauricio G",
      "userId": "11362846738805154876"
     },
     "user_tz": -60
    },
    "id": "I049dtNCBbX-",
    "outputId": "2cc1174e-550a-4a7e-84b6-6e79418edfab"
   },
   "outputs": [],
   "source": [
    "len(mse_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1705156331404,
     "user": {
      "displayName": "Mauricio G",
      "userId": "11362846738805154876"
     },
     "user_tz": -60
    },
    "id": "ad1V6JEeIz3V",
    "outputId": "456dc782-f5a6-4df6-cb02-3cdd35c8934c"
   },
   "outputs": [],
   "source": [
    "min(mse_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1705156333213,
     "user": {
      "displayName": "Mauricio G",
      "userId": "11362846738805154876"
     },
     "user_tz": -60
    },
    "id": "HsKOqXFWJTGk",
    "outputId": "bbe68b69-390b-4440-cba8-0fb8c645b948"
   },
   "outputs": [],
   "source": [
    "max(psnr_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WyCieKu-JW_e"
   },
   "outputs": [],
   "source": [
    "torch.max(sinog_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HqCYbPMZJdMp"
   },
   "outputs": [],
   "source": [
    "torch.save(img_siren.state_dict(),'img_rec_1e4.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zPlPNv4f_yr4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHYEWpVCFBSy"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 510,
     "status": "ok",
     "timestamp": 1710491350008,
     "user": {
      "displayName": "Aureo Henrique e Silva Marques",
      "userId": "11759006475363718695"
     },
     "user_tz": -60
    },
    "id": "P5WrkRJzNFcV",
    "outputId": "ddeabf25-4892-48ba-8ea0-d3a2bd67b4d7"
   },
   "outputs": [],
   "source": [
    "#!pip install -q condacolab\n",
    "import condacolab\n",
    "condacolab.install()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
